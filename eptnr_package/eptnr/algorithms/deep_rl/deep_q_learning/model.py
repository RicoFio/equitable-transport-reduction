import torch
import torch.nn as nn
import torch.nn.functional as F

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class DQN(nn.Module):

    def __init__(self, num_actions: int):
        super(DQN, self).__init__()

        hidden_size = num_actions + 10

        self.lin1 = nn.Linear(num_actions, hidden_size)
        # self.lin2 = nn.Linear(hidden_size, hidden_size)
        # self.lin3 = nn.Linear(hidden_size, hidden_size)

        self.head = nn.Linear(hidden_size, num_actions)

    # Called with either one element to determine next action, or a batch
    # during optimization. Returns tensor([[left0exp,right0exp]...]).
    def forward(self, x):
        x = x.to(device)
        x = F.relu(self.lin1(x))
        # x = F.relu(self.lin2(x))
        # x = F.relu(self.lin3(x))
        return self.head(x)
